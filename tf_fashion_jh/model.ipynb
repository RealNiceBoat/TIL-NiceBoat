{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TF Version:2.2.0  |  GPU:PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "device = tf.config.list_physical_devices('GPU')[0]\n",
    "tf.config.experimental.set_memory_growth(device, True)\n",
    "print(f'TF Version:{tf.__version__}  |  GPU:{device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "from pathlib import Path\n",
    "base_folder = Path('.')\n",
    "data_folder = base_folder/'til2020'\n",
    "train_imgs_folder = data_folder/'train'/'train'\n",
    "train_annotations = data_folder/'train.json'\n",
    "val_imgs_folder = data_folder/'val'/'val'\n",
    "val_annotations = data_folder/'val.json'\n",
    "\n",
    "train_pickle = data_folder/'train.p'/'train.p'\n",
    "val_pickle = data_folder/'val.p'/'val.p'\n",
    "\n",
    "save_model_folder = base_folder/'ckpts'\n",
    "load_model_folder = base_folder/'ckpts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    cat_list = ['tops', 'trousers', 'outerwear', 'dresses', 'skirts']\n",
    "\n",
    "    input_shape = (224,224,3)\n",
    "    wt_decay = 5e-4\n",
    "\n",
    "    dims_list = [(7,7),(14,14)]\n",
    "    aspect_ratios = [(1,1), (1,2), (2,1)]\n",
    "\n",
    "    batch_size = 16\n",
    "    epoch_warmup = 300\n",
    "    epoch_finetune = 300\n",
    "conf = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses\n",
    "# Shape of ypred: ( batch, i, j, aspect_ratios, 1+4+numclasses ). For a batch,i,j, we get #aspect_ratios vectors of length 7.\n",
    "# Shape of ytrue: ( batch, i, j, aspect_ratios, 1+4+numclasses+2 ). For a batch,i,j, we get #aspect_ratios vectors of length 9 (two more for objectness and cat/loc indicators)\n",
    "def custom_loss(ytrue, ypred):\n",
    "    obj_loss_weight = 1.0\n",
    "    cat_loss_weight = 1.0\n",
    "    loc_loss_weight = 1.0\n",
    "\n",
    "    end_cat = len(conf.cat_list) + 1\n",
    "\n",
    "    objloss_indicators = ytrue[:,:,:,:,-2:-1]\n",
    "    catlocloss_indicators = ytrue[:,:,:,:,-1:]\n",
    "\n",
    "    ytrue_obj, ypred_obj = ytrue[:,:,:,:,:1], ypred[:,:,:,:,:1]\n",
    "    ytrue_obj = tf.where( objloss_indicators != 0, ytrue_obj, 0 )\n",
    "    ypred_obj = tf.where( objloss_indicators != 0, ypred_obj, 0 )\n",
    "    objectness_loss = losses.BinaryCrossentropy(from_logits=True)( ytrue_obj, ypred_obj )\n",
    "\n",
    "    ytrue_cat, ypred_cat = ytrue[:,:,:,:,1:end_cat], ypred[:,:,:,:,1:end_cat]\n",
    "    ytrue_cat = tf.where( catlocloss_indicators != 0, ytrue_cat, 0 )\n",
    "    ypred_cat = tf.where( catlocloss_indicators != 0, ypred_cat, 0 )\n",
    "    categorical_loss = losses.CategoricalCrossentropy(from_logits=True) ( ytrue_cat, ypred_cat )\n",
    "\n",
    "    # Remember that ytrue is longer than ypred, so we will need to stop at index -2, which is where the indicators are stored\n",
    "    ytrue_loc, ypred_loc = ytrue[:,:,:,:,end_cat:-2], ypred[:,:,:,:,end_cat:]\n",
    "    ytrue_loc = tf.where( catlocloss_indicators != 0, ytrue_loc, 0 )\n",
    "    ypred_loc = tf.where( catlocloss_indicators != 0, ypred_loc, 0 )\n",
    "    localisation_loss = losses.Huber() ( ytrue_loc, ypred_loc )\n",
    "\n",
    "    return obj_loss_weight*objectness_loss + cat_loss_weight*categorical_loss + loc_loss_weight*localisation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ah functional paradigm\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "#I wrote this to reduce code size (sequential layers with activation of ReLU)\n",
    "def seq_with_activation(lst):\n",
    "    def wrapper(x):\n",
    "        nonlocal lst\n",
    "        try: iter(lst)\n",
    "        except TypeError: lst = [lst]\n",
    "        for l in lst:\n",
    "            x = l(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.LeakyReLU(0.01)(x)\n",
    "        return x\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def transfer_model_7x7_14x14(backbone_model, input_shape, dims_list, num_aspect_ratios, num_classes, wt_decay, model_name='transfer-objdet-model-7x7-14x14'):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    intermediate_layer_model = keras.Model(inputs=backbone_model.input,\n",
    "                                            outputs=backbone_model.get_layer('conv4_block6_out').output)\n",
    "    intermediate_output = intermediate_layer_model(inputs) #14\n",
    "    backbone_output = backbone_model(inputs) #7\n",
    "\n",
    "    upsample = seq_with_activation([\n",
    "        layers.Conv2D(512, 1, padding='same', kernel_regularizer=l2(wt_decay)), #7\n",
    "        layers.Conv2D(1024, 3, padding='same', kernel_regularizer=l2(wt_decay)), #7\n",
    "        layers.Conv2D(512, 1, padding='same', kernel_regularizer=l2(wt_decay)), #7\n",
    "        layers.Conv2D(1024, 3, padding='same', kernel_regularizer=l2(wt_decay)), #7\n",
    "        layers.Conv2D(512, 1, padding='same', kernel_regularizer=l2(wt_decay)), #7\n",
    "    ])(backbone_output)\n",
    "\n",
    "    x = seq_with_activation([\n",
    "        layers.Conv2D(256, 1, padding='same', kernel_regularizer=l2(wt_decay)), #7\n",
    "        layers.Conv2DTranspose(512, 5, strides=(2, 2), padding='same'), #14\n",
    "    ])(upsample)\n",
    "    x = layers.Concatenate()([x,intermediate_output])\n",
    "\n",
    "    tens_14x14 = seq_with_activation([\n",
    "        layers.Conv2D(256, 1, padding='same', kernel_regularizer=l2(wt_decay)), #14\n",
    "        layers.Conv2D(512, 3, padding='same', kernel_regularizer=l2(wt_decay)), #14\n",
    "        layers.Conv2D(256, 1, padding='same', kernel_regularizer=l2(wt_decay)), #14\n",
    "        layers.Conv2D(512, 3, padding='same', kernel_regularizer=l2(wt_decay)), #14\n",
    "        layers.Conv2D(256, 1, padding='same', kernel_regularizer=l2(wt_decay)), #14\n",
    "        layers.Conv2D(512, 3, padding='same', kernel_regularizer=l2(wt_decay)), #14\n",
    "    ])(x)\n",
    "\n",
    "    tens_7x7 = layers.Add()([\n",
    "        seq_with_activation(layers.Conv2D(2048, 3, padding='same', kernel_regularizer=l2(wt_decay)))(upsample),\n",
    "        backbone_output\n",
    "    ])\n",
    "\n",
    "    dim_tensor_map = {'7x7':tens_7x7,'14x14':tens_14x14}\n",
    "\n",
    "    #Accumulate predictions for 7x7,14x14 into a dictionary for keras multi labels.\n",
    "    preds_dict = {}\n",
    "    for dims in dims_list:\n",
    "        dimkey = '{}x{}'.format(*dims)\n",
    "        tens = dim_tensor_map[dimkey]\n",
    "        ar_preds = []\n",
    "        for _ in range(num_aspect_ratios):\n",
    "            objectness_preds = layers.Conv2D(1, 1, kernel_regularizer=l2(wt_decay))( tens )\n",
    "            class_preds = layers.Conv2D(num_classes, 1, kernel_regularizer=l2(wt_decay))( tens )\n",
    "            bbox_preds = layers.Conv2D(4, 1, kernel_regularizer=l2(wt_decay))( tens )\n",
    "            ar_preds.append( layers.Concatenate()([objectness_preds, class_preds, bbox_preds]) )\n",
    "\n",
    "        if num_aspect_ratios > 1: predictions = layers.Concatenate()(ar_preds)\n",
    "        elif num_aspect_ratios == 1: predictions = ar_preds[0]\n",
    "\n",
    "        predictions = layers.Reshape( (*dims, num_aspect_ratios, 5+num_classes), name=dimkey )(predictions)\n",
    "        preds_dict[dimkey] = predictions\n",
    "\n",
    "    model = keras.Model(inputs, preds_dict, name=model_name)\n",
    "\n",
    "    model.compile( optimizer=keras.optimizers.Adam(1e-5),\n",
    "                    loss=custom_loss )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_monitors(save_path):\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=save_path,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_loss',\n",
    "        mode='auto',\n",
    "        save_best_only=True\n",
    "    )\n",
    "    earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-8)\n",
    "    return [model_checkpoint_callback,earlystopping,reduce_lr]\n",
    "\n",
    "def train(model,warmup=True):\n",
    "    if warmup: \n",
    "        save_model_path = save_model_folder/f'pt-{model_context}-best_val_loss.h5'\n",
    "        for layer in backbone_model.layers: layer.trainable = False #dont train pretrained during warm up\n",
    "    else:\n",
    "        save_model_path = save_model_folder/f'ft-{model_context}-best_val_loss.h5'\n",
    "        for layer in model.get_layer('resnet50').layers: layer.trainable = True\n",
    "\n",
    "    model.fit(\n",
    "        x=train_sequence, \n",
    "        epochs=(conf.epoch_warmup if warmup else conf.epoch_finetune), \n",
    "        validation_data=val_sequence, \n",
    "        callbacks=model_monitors(save_model_path),\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model-7x7-14x14-3aspect-modyoloposneg-wd0.0005-res50\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nresnet50 (Model)                (None, 7, 7, 2048)   23587712    input_2[0][0]                    \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 7, 7, 512)    1049088     resnet50[1][0]                   \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 7, 7, 512)    2048        conv2d[0][0]                     \n__________________________________________________________________________________________________\nleaky_re_lu (LeakyReLU)         (None, 7, 7, 512)    0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 7, 7, 1024)   4719616     leaky_re_lu[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 7, 7, 1024)   4096        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)       (None, 7, 7, 1024)   0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 7, 7, 512)    524800      leaky_re_lu_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 7, 7, 512)    2048        conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 512)    0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 7, 7, 1024)   4719616     leaky_re_lu_2[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 7, 7, 1024)   4096        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)       (None, 7, 7, 1024)   0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 7, 7, 512)    524800      leaky_re_lu_3[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 7, 7, 512)    2048        conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)       (None, 7, 7, 512)    0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 7, 7, 256)    131328      leaky_re_lu_4[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 7, 7, 256)    1024        conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)       (None, 7, 7, 256)    0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nconv2d_transpose (Conv2DTranspo (None, 14, 14, 512)  3277312     leaky_re_lu_5[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 14, 14, 512)  2048        conv2d_transpose[0][0]           \n__________________________________________________________________________________________________\nleaky_re_lu_6 (LeakyReLU)       (None, 14, 14, 512)  0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nmodel (Model)                   (None, 14, 14, 1024) 8589184     input_2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 14, 14, 1536) 0           leaky_re_lu_6[0][0]              \n                                                                 model[1][0]                      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 14, 14, 256)  393472      concatenate[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 14, 14, 256)  1024        conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_7 (LeakyReLU)       (None, 14, 14, 256)  0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 14, 14, 512)  1180160     leaky_re_lu_7[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 14, 14, 512)  2048        conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_8 (LeakyReLU)       (None, 14, 14, 512)  0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 14, 14, 256)  131328      leaky_re_lu_8[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 14, 14, 256)  1024        conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_9 (LeakyReLU)       (None, 14, 14, 256)  0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 14, 14, 512)  1180160     leaky_re_lu_9[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 14, 14, 512)  2048        conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_10 (LeakyReLU)      (None, 14, 14, 512)  0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 14, 14, 256)  131328      leaky_re_lu_10[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 14, 14, 256)  1024        conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nleaky_re_lu_11 (LeakyReLU)      (None, 14, 14, 256)  0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 7, 7, 2048)   9439232     leaky_re_lu_4[0][0]              \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 14, 14, 512)  1180160     leaky_re_lu_11[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 7, 7, 2048)   8192        conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 14, 14, 512)  2048        conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nleaky_re_lu_13 (LeakyReLU)      (None, 7, 7, 2048)   0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nleaky_re_lu_12 (LeakyReLU)      (None, 14, 14, 512)  0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nadd (Add)                       (None, 7, 7, 2048)   0           leaky_re_lu_13[0][0]             \n                                                                 resnet50[1][0]                   \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 14, 14, 1)    513         leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 14, 14, 5)    2565        leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 14, 14, 4)    2052        leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 14, 14, 1)    513         leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 14, 14, 5)    2565        leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 14, 14, 4)    2052        leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_28 (Conv2D)              (None, 14, 14, 1)    513         leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 14, 14, 5)    2565        leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 14, 14, 4)    2052        leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 7, 7, 1)      2049        add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 7, 7, 5)      10245       add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 7, 7, 4)      8196        add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 7, 7, 1)      2049        add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 7, 7, 5)      10245       add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 7, 7, 4)      8196        add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 7, 7, 1)      2049        add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 7, 7, 5)      10245       add[0][0]                        \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 7, 7, 4)      8196        add[0][0]                        \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 14, 14, 10)   0           conv2d_22[0][0]                  \n                                                                 conv2d_23[0][0]                  \n                                                                 conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 14, 14, 10)   0           conv2d_25[0][0]                  \n                                                                 conv2d_26[0][0]                  \n                                                                 conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 14, 14, 10)   0           conv2d_28[0][0]                  \n                                                                 conv2d_29[0][0]                  \n                                                                 conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 7, 7, 10)     0           conv2d_13[0][0]                  \n                                                                 conv2d_14[0][0]                  \n                                                                 conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 7, 7, 10)     0           conv2d_16[0][0]                  \n                                                                 conv2d_17[0][0]                  \n                                                                 conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 7, 7, 10)     0           conv2d_19[0][0]                  \n                                                                 conv2d_20[0][0]                  \n                                                                 conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_8 (Concatenate)     (None, 14, 14, 30)   0           concatenate_5[0][0]              \n                                                                 concatenate_6[0][0]              \n                                                                 concatenate_7[0][0]              \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 7, 7, 30)     0           concatenate_1[0][0]              \n                                                                 concatenate_2[0][0]              \n                                                                 concatenate_3[0][0]              \n__________________________________________________________________________________________________\n14x14 (Reshape)                 (None, 14, 14, 3, 10 0           concatenate_8[0][0]              \n__________________________________________________________________________________________________\n7x7 (Reshape)                   (None, 7, 7, 3, 10)  0           concatenate_4[0][0]              \n==================================================================================================\nTotal params: 52,281,788\nTrainable params: 52,211,260\nNon-trainable params: 70,528\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model_context = 'model-7x7-14x14-3aspect-modyoloposneg-wd{}'.format(conf.wt_decay)\n",
    "# load_model_path = os.path.join( load_model_folder, '{}-best_val_loss.h5'.format(model_context) )\n",
    "load_model_path = None\n",
    "\n",
    "if load_model_path is None:\n",
    "    backbone_model = keras.applications.ResNet50(input_shape=conf.input_shape,include_top=False)\n",
    "    model = transfer_model_7x7_14x14(backbone_model,\n",
    "        input_shape=conf.input_shape,\n",
    "        dims_list=conf.dims_list,\n",
    "        num_aspect_ratios=len(conf.aspect_ratios),\n",
    "        num_classes=len(conf.cat_list),\n",
    "        wt_decay=conf.wt_decay,\n",
    "        model_name=model_context+'-res50')\n",
    "else:\n",
    "    model = keras.models.load_model(load_model_path, custom_objects={'custom_loss':custom_loss})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.loader import TILSequence,TILPickle\n",
    "from scripts.sampling import iou,modified_yolo_posneg_sampling\n",
    "from scripts.augment import aug_default,aug_identity\n",
    "from scripts.encoder import encode_label\n",
    "\n",
    "label_encoder = lambda y: encode_label(y, conf.dims_list, conf.aspect_ratios, iou, modified_yolo_posneg_sampling, conf.cat_list)\n",
    "preproc_fn = lambda x: x / 255.\n",
    "\n",
    "if True:\n",
    "    train_sequence = TILPickle(train_pickle, conf.batch_size, aug_default, (224,224), label_encoder, preproc_fn)\n",
    "    val_sequence = TILPickle(val_pickle, conf.batch_size, aug_identity, (224,224), label_encoder, preproc_fn)\n",
    "else:\n",
    "    train_sequence = TILSequence(train_imgs_folder,train_annotations,conf.batch_size,aug_default,(224,224),label_encoder,preproc_fn)\n",
    "    val_sequence = TILSequence(val_imgs_folder,val_annotations,conf.batch_size,aug_identity,(224,224),label_encoder,preproc_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Warming up the model...\nEpoch 1/300\n"
    },
    {
     "output_type": "error",
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model-7x7-14x14-3aspect-modyoloposneg-wd0.0005-res50/model/conv1_conv/Conv2D (defined at <ipython-input-6-fdbb8334950d>:21) ]] [Op:__inference_train_function_37432]\n\nFunction call stack:\ntrain_function\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-698727cff69f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Warming up the model...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwarmup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Fine tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model warmed. Loading best val version of model...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-fdbb8334950d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, warmup)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'resnet50'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     model.fit(\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_sequence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_warmup\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwarmup\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_finetune\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\TIL\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\TIL\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\TIL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\TIL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\TIL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\TIL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\TIL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\TIL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\TIL\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model-7x7-14x14-3aspect-modyoloposneg-wd0.0005-res50/model/conv1_conv/Conv2D (defined at <ipython-input-6-fdbb8334950d>:21) ]] [Op:__inference_train_function_37432]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "print('Warming up the model...')\n",
    "train(model,warmup=True)\n",
    "\n",
    "# Fine tuning\n",
    "print('Model warmed. Loading best val version of model...')\n",
    "del model\n",
    "load_model_path = load_model_folder/f'pt-{model_context}-best_val_loss.h5'\n",
    "model = keras.models.load_model(load_model_path, custom_objects={'custom_loss':custom_loss})\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-5),loss=custom_loss)\n",
    "train(model,warmup=False)\n",
    "\n",
    "# Final save\n",
    "model.save(os.path.join(save_model_folder, 'ft-{}-final.h5'.format(model_context)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(174, 159, 3)\n(224, 224, 3)\n(224, 224, 3)\n(224, 224, 3)\n(197, 171, 3)\n(224, 224, 3)\n(224, 224, 3)\n(224, 224, 3)\n(224, 224, 3)\n(224, 224, 3)\n(224, 224, 3)\n(92, 86, 3)\n(224, 224, 3)\n(224, 224, 3)\n(224, 224, 3)\n(224, 224, 3)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([array([[[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       ...,\n\n       [[0.65882353, 0.70588235, 0.76470588],\n        [0.68627451, 0.73333333, 0.80392157],\n        [0.65882353, 0.70980392, 0.77254902],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.68235294, 0.71764706, 0.78823529],\n        [0.66666667, 0.71372549, 0.77647059],\n        [0.65098039, 0.69803922, 0.76078431],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.64313725, 0.68627451, 0.74509804],\n        [0.64313725, 0.69411765, 0.74901961],\n        [0.63921569, 0.69019608, 0.76078431],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]]]),\n       array([[[0.74509804, 0.81568627, 0.85882353],\n        [0.74117647, 0.81176471, 0.85882353],\n        [0.74117647, 0.81960784, 0.8627451 ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.74509804, 0.81568627, 0.85490196],\n        [0.74901961, 0.81568627, 0.85490196],\n        [0.74509804, 0.81568627, 0.85098039],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.74117647, 0.81568627, 0.84705882],\n        [0.74901961, 0.80784314, 0.84313725],\n        [0.74509804, 0.80784314, 0.84313725],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       ...,\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]]]),\n       array([[[0.85098039, 0.8       , 0.70980392],\n        [0.8627451 , 0.80392157, 0.70196078],\n        [0.75294118, 0.67843137, 0.56078431],\n        ...,\n        [0.69019608, 0.56862745, 0.43137255],\n        [0.68627451, 0.58039216, 0.43137255],\n        [0.6745098 , 0.58039216, 0.42352941]],\n\n       [[0.85882353, 0.80392157, 0.71764706],\n        [0.85882353, 0.79607843, 0.69803922],\n        [0.75686275, 0.67843137, 0.56078431],\n        ...,\n        [0.69019608, 0.59215686, 0.46666667],\n        [0.69019608, 0.59215686, 0.4627451 ],\n        [0.68627451, 0.59607843, 0.45882353]],\n\n       [[0.8627451 , 0.80392157, 0.71764706],\n        [0.85490196, 0.78431373, 0.68627451],\n        [0.75686275, 0.67058824, 0.55686275],\n        ...,\n        [0.6745098 , 0.58823529, 0.46666667],\n        [0.67843137, 0.58823529, 0.46666667],\n        [0.68235294, 0.59215686, 0.46666667]],\n\n       ...,\n\n       [[0.49019608, 0.40392157, 0.18431373],\n        [0.49803922, 0.4       , 0.18823529],\n        [0.50196078, 0.39607843, 0.19215686],\n        ...,\n        [0.08627451, 0.04313725, 0.00392157],\n        [0.09019608, 0.04313725, 0.00392157],\n        [0.09411765, 0.04313725, 0.00784314]],\n\n       [[0.49019608, 0.40392157, 0.17647059],\n        [0.49803922, 0.4       , 0.18431373],\n        [0.49411765, 0.39215686, 0.18431373],\n        ...,\n        [0.09411765, 0.02745098, 0.00784314],\n        [0.09019608, 0.03529412, 0.01568627],\n        [0.07843137, 0.03137255, 0.01960784]],\n\n       [[0.49019608, 0.40392157, 0.17647059],\n        [0.49803922, 0.40392157, 0.18039216],\n        [0.49803922, 0.39607843, 0.18039216],\n        ...,\n        [0.06666667, 0.        , 0.        ],\n        [0.0627451 , 0.00392157, 0.00392157],\n        [0.05098039, 0.00784314, 0.00784314]]]),\n       array([[[0.11372549, 0.14509804, 0.0627451 ],\n        [0.10588235, 0.12941176, 0.0627451 ],\n        [0.05882353, 0.06666667, 0.05490196],\n        ...,\n        [0.1254902 , 0.16862745, 0.06666667],\n        [0.16470588, 0.19607843, 0.0745098 ],\n        [0.37254902, 0.41960784, 0.2       ]],\n\n       [[0.10196078, 0.12156863, 0.0745098 ],\n        [0.05490196, 0.0745098 , 0.03529412],\n        [0.06666667, 0.07843137, 0.05098039],\n        ...,\n        [0.1372549 , 0.14509804, 0.07058824],\n        [0.16862745, 0.17647059, 0.08235294],\n        [0.31372549, 0.3254902 , 0.14509804]],\n\n       [[0.11372549, 0.17254902, 0.04705882],\n        [0.10980392, 0.15686275, 0.05098039],\n        [0.1254902 , 0.17647059, 0.07058824],\n        ...,\n        [0.25098039, 0.25882353, 0.14117647],\n        [0.31764706, 0.31372549, 0.18431373],\n        [0.31764706, 0.34901961, 0.1372549 ]],\n\n       ...,\n\n       [[0.13333333, 0.11764706, 0.08235294],\n        [0.16078431, 0.09411765, 0.08627451],\n        [0.29411765, 0.24705882, 0.14901961],\n        ...,\n        [0.18431373, 0.23529412, 0.10588235],\n        [0.14901961, 0.18823529, 0.08235294],\n        [0.20392157, 0.27058824, 0.11764706]],\n\n       [[0.14901961, 0.13333333, 0.08235294],\n        [0.12941176, 0.11372549, 0.08235294],\n        [0.22745098, 0.23529412, 0.12156863],\n        ...,\n        [0.20784314, 0.25098039, 0.10980392],\n        [0.2       , 0.25882353, 0.10196078],\n        [0.21176471, 0.23921569, 0.12941176]],\n\n       [[0.30980392, 0.3254902 , 0.20784314],\n        [0.29019608, 0.28235294, 0.18823529],\n        [0.24313725, 0.2745098 , 0.12941176],\n        ...,\n        [0.21568627, 0.28627451, 0.12156863],\n        [0.16470588, 0.20392157, 0.0745098 ],\n        [0.14901961, 0.12941176, 0.09803922]]]),\n       array([[[0.79607843, 0.89019608, 0.97647059],\n        [0.78039216, 0.85882353, 0.94901961],\n        [0.77254902, 0.8627451 , 0.94117647],\n        ...,\n        [0.89019608, 0.95686275, 0.99607843],\n        [0.89019608, 0.95686275, 1.        ],\n        [0.89019608, 0.95686275, 0.99607843]],\n\n       [[0.76078431, 0.83921569, 0.91372549],\n        [0.78039216, 0.8627451 , 0.94117647],\n        [0.75294118, 0.83529412, 0.91372549],\n        ...,\n        [0.89019608, 0.95686275, 0.99607843],\n        [0.89411765, 0.96078431, 1.        ],\n        [0.89411765, 0.96078431, 1.        ]],\n\n       [[0.79215686, 0.86666667, 0.96078431],\n        [0.78823529, 0.85490196, 0.94117647],\n        [0.79215686, 0.87058824, 0.96078431],\n        ...,\n        [0.89411765, 0.96078431, 1.        ],\n        [0.89803922, 0.96078431, 1.        ],\n        [0.89411765, 0.96078431, 1.        ]],\n\n       ...,\n\n       [[0.23921569, 0.18823529, 0.15686275],\n        [0.61176471, 0.50588235, 0.41568627],\n        [0.41176471, 0.35686275, 0.29019608],\n        ...,\n        [0.11372549, 0.14117647, 0.06666667],\n        [0.12156863, 0.15294118, 0.0745098 ],\n        [0.11372549, 0.14509804, 0.06666667]],\n\n       [[0.18431373, 0.15686275, 0.13333333],\n        [0.24705882, 0.17254902, 0.14901961],\n        [0.11372549, 0.10588235, 0.09019608],\n        ...,\n        [0.10980392, 0.1372549 , 0.0745098 ],\n        [0.10980392, 0.13333333, 0.0627451 ],\n        [0.12156863, 0.14901961, 0.0627451 ]],\n\n       [[0.14117647, 0.14117647, 0.11372549],\n        [0.09803922, 0.10196078, 0.08627451],\n        [0.10196078, 0.10196078, 0.08627451],\n        ...,\n        [0.10980392, 0.14117647, 0.07058824],\n        [0.09411765, 0.1254902 , 0.05882353],\n        [0.09803922, 0.1254902 , 0.05882353]]]),\n       array([[[1.        , 0.38039216, 0.24313725],\n        [1.        , 0.38039216, 0.25490196],\n        [1.        , 0.38039216, 0.25490196],\n        ...,\n        [0.94901961, 0.29019608, 0.25490196],\n        [0.97254902, 0.32156863, 0.28627451],\n        [0.98431373, 0.34117647, 0.29803922]],\n\n       [[1.        , 0.38039216, 0.25490196],\n        [1.        , 0.38039216, 0.25490196],\n        [1.        , 0.38431373, 0.26666667],\n        ...,\n        [0.79215686, 0.23529412, 0.20392157],\n        [0.82352941, 0.25490196, 0.22745098],\n        [0.83921569, 0.23529412, 0.24313725]],\n\n       [[1.        , 0.38431373, 0.2745098 ],\n        [1.        , 0.39215686, 0.2745098 ],\n        [1.        , 0.38431373, 0.25882353],\n        ...,\n        [0.83921569, 0.26666667, 0.24705882],\n        [0.86666667, 0.29019608, 0.26666667],\n        [0.89019608, 0.29019608, 0.27843137]],\n\n       ...,\n\n       [[0.76078431, 0.70196078, 0.70196078],\n        [0.78039216, 0.67058824, 0.70196078],\n        [0.80392157, 0.74901961, 0.72156863],\n        ...,\n        [0.73333333, 0.67058824, 0.67843137],\n        [0.61568627, 0.60392157, 0.62352941],\n        [0.53333333, 0.54901961, 0.61176471]],\n\n       [[0.62745098, 0.59607843, 0.63529412],\n        [0.68627451, 0.61176471, 0.65490196],\n        [0.58431373, 0.56470588, 0.62352941],\n        ...,\n        [0.62745098, 0.63529412, 0.67058824],\n        [0.72156863, 0.69803922, 0.70980392],\n        [0.77254902, 0.72941176, 0.72156863]],\n\n       [[0.79607843, 0.75294118, 0.72156863],\n        [0.85490196, 0.78431373, 0.73333333],\n        [0.79607843, 0.71764706, 0.70196078],\n        ...,\n        [1.        , 0.85882353, 0.80392157],\n        [0.89803922, 0.81176471, 0.75294118],\n        [0.70196078, 0.68627451, 0.66666667]]]),\n       array([[[0.38431373, 0.37254902, 0.47843137],\n        [0.40392157, 0.37647059, 0.49803922],\n        [0.41568627, 0.39607843, 0.48627451],\n        ...,\n        [0.58039216, 0.6       , 0.72941176],\n        [0.56862745, 0.58823529, 0.71764706],\n        [0.57647059, 0.57647059, 0.70980392]],\n\n       [[0.40784314, 0.39607843, 0.50588235],\n        [0.42745098, 0.40392157, 0.50588235],\n        [0.43529412, 0.41568627, 0.51372549],\n        ...,\n        [0.62745098, 0.63137255, 0.76078431],\n        [0.6       , 0.61568627, 0.74117647],\n        [0.59607843, 0.6       , 0.71764706]],\n\n       [[0.43529412, 0.42352941, 0.5372549 ],\n        [0.44705882, 0.43529412, 0.52941176],\n        [0.4627451 , 0.44313725, 0.54901961],\n        ...,\n        [0.68235294, 0.69019608, 0.81176471],\n        [0.65882353, 0.66666667, 0.79215686],\n        [0.64705882, 0.64705882, 0.76862745]],\n\n       ...,\n\n       [[0.3254902 , 0.27058824, 0.21176471],\n        [0.49411765, 0.38431373, 0.27058824],\n        [0.4745098 , 0.32156863, 0.19215686],\n        ...,\n        [0.39215686, 0.27058824, 0.19215686],\n        [0.40392157, 0.2627451 , 0.18823529],\n        [0.3254902 , 0.2       , 0.12156863]],\n\n       [[0.42745098, 0.31372549, 0.21176471],\n        [0.46666667, 0.34509804, 0.22352941],\n        [0.48627451, 0.34509804, 0.21960784],\n        ...,\n        [0.37254902, 0.25490196, 0.17254902],\n        [0.4745098 , 0.33333333, 0.23921569],\n        [0.37254902, 0.23921569, 0.15294118]],\n\n       [[0.42352941, 0.31372549, 0.20392157],\n        [0.4745098 , 0.35686275, 0.23137255],\n        [0.51372549, 0.37647059, 0.25490196],\n        ...,\n        [0.30196078, 0.18039216, 0.11764706],\n        [0.33333333, 0.22352941, 0.15294118],\n        [0.37254902, 0.24313725, 0.15294118]]]),\n       array([[[0.60392157, 0.59607843, 0.50196078],\n        [0.60392157, 0.6       , 0.50196078],\n        [0.60392157, 0.60392157, 0.50196078],\n        ...,\n        [0.56470588, 0.54901961, 0.43921569],\n        [0.52941176, 0.52156863, 0.41568627],\n        [0.55686275, 0.54509804, 0.46666667]],\n\n       [[0.59607843, 0.60392157, 0.49803922],\n        [0.59607843, 0.60392157, 0.50196078],\n        [0.60392157, 0.60392157, 0.50196078],\n        ...,\n        [0.57254902, 0.55686275, 0.44705882],\n        [0.51764706, 0.51372549, 0.4       ],\n        [0.55294118, 0.54117647, 0.4627451 ]],\n\n       [[0.61176471, 0.6       , 0.51372549],\n        [0.61176471, 0.59607843, 0.50588235],\n        [0.60392157, 0.60392157, 0.50196078],\n        ...,\n        [0.58431373, 0.56470588, 0.44705882],\n        [0.52941176, 0.50588235, 0.40784314],\n        [0.55294118, 0.54509804, 0.4627451 ]],\n\n       ...,\n\n       [[0.78039216, 0.74509804, 0.67843137],\n        [0.78039216, 0.74901961, 0.67843137],\n        [0.77647059, 0.74901961, 0.6745098 ],\n        ...,\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ]],\n\n       [[0.78039216, 0.75294118, 0.67843137],\n        [0.77647059, 0.75294118, 0.6745098 ],\n        [0.77647059, 0.75294118, 0.69411765],\n        ...,\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ]],\n\n       [[0.78039216, 0.75294118, 0.68235294],\n        [0.77647059, 0.75294118, 0.68235294],\n        [0.77254902, 0.75294118, 0.69411765],\n        ...,\n        [0.99607843, 0.99607843, 0.99607843],\n        [0.99607843, 1.        , 0.99607843],\n        [1.        , 1.        , 1.        ]]]),\n       array([[[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ]],\n\n       ...,\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.99215686, 0.82745098, 0.83529412],\n        [0.99215686, 0.82745098, 0.83529412],\n        [0.99215686, 0.82745098, 0.83529412]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.99215686, 0.82745098, 0.83529412],\n        [0.99215686, 0.82745098, 0.83529412],\n        [0.99215686, 0.82745098, 0.83529412]],\n\n       [[0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.99215686, 0.82745098, 0.83529412],\n        [0.99215686, 0.82745098, 0.83529412],\n        [0.99215686, 0.82745098, 0.83529412]]]),\n       array([[[0.30980392, 0.30980392, 0.32156863],\n        [0.31372549, 0.32156863, 0.32941176],\n        [0.30980392, 0.31372549, 0.3254902 ],\n        ...,\n        [0.47843137, 0.49411765, 0.49803922],\n        [0.48235294, 0.49019608, 0.49803922],\n        [0.47843137, 0.48235294, 0.49803922]],\n\n       [[0.30980392, 0.31372549, 0.3254902 ],\n        [0.31372549, 0.32156863, 0.32941176],\n        [0.31372549, 0.32156863, 0.32941176],\n        ...,\n        [0.49019608, 0.49411765, 0.50588235],\n        [0.49019608, 0.49411765, 0.50588235],\n        [0.49019608, 0.49411765, 0.49803922]],\n\n       [[0.31372549, 0.32156863, 0.32941176],\n        [0.31372549, 0.32156863, 0.32941176],\n        [0.32156863, 0.3254902 , 0.3372549 ],\n        ...,\n        [0.49019608, 0.49411765, 0.50588235],\n        [0.49019608, 0.49411765, 0.50588235],\n        [0.49019608, 0.49411765, 0.50588235]],\n\n       ...,\n\n       [[1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        ...,\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ]],\n\n       [[1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        ...,\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ]],\n\n       [[1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        ...,\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ]]]),\n       array([[[0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        ...,\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647]],\n\n       [[0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.30196078, 0.2745098 , 0.28235294],\n        ...,\n        [0.34117647, 0.3372549 , 0.3372549 ],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647]],\n\n       [[0.34117647, 0.34117647, 0.34117647],\n        [0.30196078, 0.2745098 , 0.28235294],\n        [0.34117647, 0.34117647, 0.33333333],\n        ...,\n        [0.0627451 , 0.02745098, 0.01960784],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647]],\n\n       ...,\n\n       [[0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.3254902 , 0.34117647],\n        [0.14117647, 0.08235294, 0.07058824],\n        ...,\n        [0.19607843, 0.13333333, 0.10196078],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647]],\n\n       [[0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        ...,\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647]],\n\n       [[0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        ...,\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647],\n        [0.34117647, 0.34117647, 0.34117647]]]),\n       array([[[1.        , 1.        , 1.        ],\n        [1.        , 0.98823529, 0.9254902 ],\n        [0.50588235, 0.18823529, 0.        ],\n        ...,\n        [0.3254902 , 0.        , 0.        ],\n        [0.32941176, 0.00392157, 0.        ],\n        [0.25098039, 0.        , 0.        ]],\n\n       [[1.        , 1.        , 1.        ],\n        [1.        , 1.        , 0.94117647],\n        [0.51764706, 0.2       , 0.        ],\n        ...,\n        [0.42745098, 0.0745098 , 0.01568627],\n        [0.41176471, 0.09803922, 0.01568627],\n        [0.34901961, 0.06666667, 0.        ]],\n\n       [[1.        , 1.        , 1.        ],\n        [1.        , 1.        , 0.9254902 ],\n        [0.49803922, 0.16470588, 0.        ],\n        ...,\n        [0.78823529, 0.46666667, 0.36862745],\n        [0.69411765, 0.4       , 0.28627451],\n        [0.79215686, 0.52941176, 0.4       ]],\n\n       ...,\n\n       [[1.        , 1.        , 1.        ],\n        [0.90196078, 0.90196078, 0.90196078],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.        , 0.        , 0.        ],\n        [0.32941176, 0.31764706, 0.29803922]],\n\n       [[1.        , 1.        , 1.        ],\n        [0.90196078, 0.90196078, 0.90588235],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.        , 0.        , 0.        ],\n        [0.08627451, 0.06666667, 0.04313725],\n        [0.40392157, 0.39215686, 0.36862745]],\n\n       [[1.        , 1.        , 1.        ],\n        [0.90196078, 0.89411765, 0.90588235],\n        [0.        , 0.        , 0.        ],\n        ...,\n        [0.00392157, 0.        , 0.        ],\n        [0.02352941, 0.00392157, 0.        ],\n        [0.1372549 , 0.12941176, 0.11764706]]]),\n       array([[[1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        ...,\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ]],\n\n       [[1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        ...,\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ]],\n\n       [[1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        ...,\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ],\n        [1.        , 1.        , 1.        ]],\n\n       ...,\n\n       [[1.        , 0.89803922, 0.79215686],\n        [0.98431373, 0.89803922, 0.76078431],\n        [0.96078431, 0.88627451, 0.74901961],\n        ...,\n        [0.99215686, 0.84705882, 0.62745098],\n        [0.96470588, 0.83921569, 0.63529412],\n        [0.94901961, 0.87058824, 0.70588235]],\n\n       [[0.96470588, 0.88627451, 0.77254902],\n        [0.96470588, 0.88627451, 0.76862745],\n        [0.98039216, 0.88235294, 0.76078431],\n        ...,\n        [1.        , 0.83529412, 0.65882353],\n        [0.96470588, 0.81960784, 0.63921569],\n        [1.        , 0.88235294, 0.7372549 ]],\n\n       [[0.97254902, 0.89411765, 0.78431373],\n        [0.95294118, 0.87058824, 0.74901961],\n        [0.96078431, 0.89411765, 0.74117647],\n        ...,\n        [1.        , 0.81568627, 0.65882353],\n        [0.98431373, 0.82745098, 0.68627451],\n        [1.        , 0.92941176, 0.83921569]]]),\n       array([[[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]],\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]],\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]],\n\n       ...,\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]],\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]],\n\n       [[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.],\n        ...,\n        [0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]]]),\n       array([[[0.52156863, 0.56078431, 0.5254902 ],\n        [0.5372549 , 0.56078431, 0.55294118],\n        [0.55686275, 0.56470588, 0.56862745],\n        ...,\n        [0.6745098 , 0.68627451, 0.63921569],\n        [0.67843137, 0.67058824, 0.63529412],\n        [0.67058824, 0.67058824, 0.64705882]],\n\n       [[0.52156863, 0.54901961, 0.53333333],\n        [0.5372549 , 0.55686275, 0.55294118],\n        [0.54901961, 0.56470588, 0.57254902],\n        ...,\n        [0.68235294, 0.67843137, 0.65098039],\n        [0.68235294, 0.67843137, 0.65098039],\n        [0.6745098 , 0.67058824, 0.64705882]],\n\n       [[0.54901961, 0.56470588, 0.55294118],\n        [0.55686275, 0.56862745, 0.56470588],\n        [0.55686275, 0.56862745, 0.57254902],\n        ...,\n        [0.69019608, 0.68627451, 0.6627451 ],\n        [0.69019608, 0.67843137, 0.6627451 ],\n        [0.6745098 , 0.67058824, 0.65490196]],\n\n       ...,\n\n       [[0.45490196, 0.48627451, 0.50196078],\n        [0.44705882, 0.47843137, 0.49803922],\n        [0.44705882, 0.48235294, 0.49803922],\n        ...,\n        [0.54901961, 0.5254902 , 0.50980392],\n        [0.53333333, 0.5254902 , 0.50196078],\n        [0.5372549 , 0.54117647, 0.51372549]],\n\n       [[0.45490196, 0.49019608, 0.49411765],\n        [0.44313725, 0.48627451, 0.49019608],\n        [0.43529412, 0.48235294, 0.48627451],\n        ...,\n        [0.55294118, 0.5372549 , 0.50980392],\n        [0.5372549 , 0.5254902 , 0.49803922],\n        [0.5254902 , 0.52156863, 0.50588235]],\n\n       [[0.43137255, 0.4745098 , 0.47843137],\n        [0.43529412, 0.47843137, 0.47843137],\n        [0.42352941, 0.47058824, 0.4627451 ],\n        ...,\n        [0.54901961, 0.5372549 , 0.50980392],\n        [0.52941176, 0.51372549, 0.49803922],\n        [0.50588235, 0.49411765, 0.48235294]]]),\n       array([[[0.83137255, 0.77254902, 0.75686275],\n        [0.83137255, 0.77254902, 0.74509804],\n        [0.82745098, 0.76078431, 0.72941176],\n        ...,\n        [0.55686275, 0.45098039, 0.32156863],\n        [0.44313725, 0.34509804, 0.27058824],\n        [0.54509804, 0.41176471, 0.29411765]],\n\n       [[0.83137255, 0.77254902, 0.74901961],\n        [0.82745098, 0.77254902, 0.74509804],\n        [0.82352941, 0.76470588, 0.73333333],\n        ...,\n        [0.47843137, 0.36470588, 0.29411765],\n        [0.43137255, 0.33333333, 0.27058824],\n        [0.58823529, 0.45882353, 0.31764706]],\n\n       [[0.83921569, 0.77254902, 0.74117647],\n        [0.83137255, 0.77647059, 0.74117647],\n        [0.82352941, 0.76078431, 0.73333333],\n        ...,\n        [0.43137255, 0.3254902 , 0.27843137],\n        [0.44705882, 0.3372549 , 0.27843137],\n        [0.54901961, 0.41960784, 0.29803922]],\n\n       ...,\n\n       [[0.93333333, 0.91764706, 0.8745098 ],\n        [0.92941176, 0.90980392, 0.86666667],\n        [0.92941176, 0.90980392, 0.87058824],\n        ...,\n        [0.54509804, 0.38823529, 0.41960784],\n        [0.56470588, 0.4       , 0.43137255],\n        [0.61568627, 0.45490196, 0.48627451]],\n\n       [[0.93333333, 0.91764706, 0.8745098 ],\n        [0.92941176, 0.90980392, 0.87058824],\n        [0.9254902 , 0.90980392, 0.86666667],\n        ...,\n        [0.54901961, 0.39215686, 0.41960784],\n        [0.56078431, 0.4       , 0.41960784],\n        [0.57647059, 0.41960784, 0.44705882]],\n\n       [[0.93333333, 0.91764706, 0.8745098 ],\n        [0.93333333, 0.91764706, 0.8745098 ],\n        [0.9254902 , 0.90980392, 0.86666667],\n        ...,\n        [0.55686275, 0.4       , 0.41568627],\n        [0.56470588, 0.40392157, 0.42352941],\n        [0.57254902, 0.41568627, 0.44313725]]])], dtype=object)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_sequence[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bittilconda431f6b117ae54518ae316f75f88a7342",
   "display_name": "Python 3.8.3 64-bit ('TIL': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}